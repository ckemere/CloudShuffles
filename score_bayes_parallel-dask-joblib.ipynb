{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score multi-session events using the replay score from Davidson et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "import nelpy as nel\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load experimental data from Google Cloud bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kemerelab-data/diba/', 'kemerelab-data/diba/gor01vvp01-metadata.h5', 'kemerelab-data/diba/gor01vvp01_processed_speed.nel', 'kemerelab-data/diba/gor01vvp01pin01-metadata.h5', 'kemerelab-data/diba/gor01vvp01pin01_processed_speed.nel']\n"
     ]
    }
   ],
   "source": [
    "import gcsfs\n",
    "import pandas as pd\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project='polar-program-784', token='cloud')\n",
    "print(fs.ls('kemerelab-data/diba'))\n",
    "\n",
    "with fs.open('kemerelab-data/diba/gor01vvp01pin01-metadata.h5', 'rb') as fid:\n",
    "    with pd.HDFStore('gor01vvp01pin01-metadata.h5', mode=\"r\", driver=\"H5FD_CORE\",\n",
    "            driver_core_backing_store=0,\n",
    "            driver_core_image=fid.read()\n",
    "            ) as store:\n",
    "        df = store['Session_Metadata']\n",
    "        df2 = store['Subset_Metadata']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit # beware - this will run it 7 times to get a time! 36 s for 1.4 GB file\n",
    "\n",
    "with fs.open('kemerelab-data/diba/gor01vvp01pin01_processed_speed.nel', 'rb') as fid:\n",
    "    jar = nel.load_pkl('',fileobj=fid) # currently requires a specific nelpy branch\n",
    "\n",
    "exp_data = jar.exp_data\n",
    "aux_data = jar.aux_data\n",
    "#del jar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define subset of sessions to score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating subset of 18 sessions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>track</th>\n",
       "      <th>segment</th>\n",
       "      <th>duration</th>\n",
       "      <th>n_cells</th>\n",
       "      <th>n_placecells</th>\n",
       "      <th>n_PBEs</th>\n",
       "      <th>Notes</th>\n",
       "      <th>prescreen_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>gor01</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22-24-40</td>\n",
       "      <td>two</td>\n",
       "      <td>short</td>\n",
       "      <td>1620.0</td>\n",
       "      <td>203</td>\n",
       "      <td>61</td>\n",
       "      <td>301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gor01</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>16-40-19</td>\n",
       "      <td>two</td>\n",
       "      <td>short</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>117</td>\n",
       "      <td>46</td>\n",
       "      <td>277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pin01</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>12-58-54</td>\n",
       "      <td>unknown</td>\n",
       "      <td>long</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>49</td>\n",
       "      <td>21</td>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pin01</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>12-58-54</td>\n",
       "      <td>unknown</td>\n",
       "      <td>short</td>\n",
       "      <td>925.0</td>\n",
       "      <td>49</td>\n",
       "      <td>26</td>\n",
       "      <td>222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gor01</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>16-40-19</td>\n",
       "      <td>two</td>\n",
       "      <td>long</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>117</td>\n",
       "      <td>43</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>gor01</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1-22-43</td>\n",
       "      <td>one</td>\n",
       "      <td>long</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>203</td>\n",
       "      <td>62</td>\n",
       "      <td>117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>gor01</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>22-24-40</td>\n",
       "      <td>two</td>\n",
       "      <td>long</td>\n",
       "      <td>912.0</td>\n",
       "      <td>203</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>gor01</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1-22-43</td>\n",
       "      <td>one</td>\n",
       "      <td>short</td>\n",
       "      <td>617.0</td>\n",
       "      <td>203</td>\n",
       "      <td>71</td>\n",
       "      <td>91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gor01</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>21-16-25</td>\n",
       "      <td>two</td>\n",
       "      <td>long</td>\n",
       "      <td>720.0</td>\n",
       "      <td>171</td>\n",
       "      <td>82</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>vvp01</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>17-29-30</td>\n",
       "      <td>one</td>\n",
       "      <td>short</td>\n",
       "      <td>490.0</td>\n",
       "      <td>68</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>vvp01</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>16-40-54</td>\n",
       "      <td>two</td>\n",
       "      <td>long</td>\n",
       "      <td>861.0</td>\n",
       "      <td>41</td>\n",
       "      <td>25</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gor01</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>21-16-25</td>\n",
       "      <td>two</td>\n",
       "      <td>short</td>\n",
       "      <td>457.0</td>\n",
       "      <td>171</td>\n",
       "      <td>64</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gor01</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>16-53-46</td>\n",
       "      <td>two</td>\n",
       "      <td>long</td>\n",
       "      <td>470.0</td>\n",
       "      <td>81</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>vvp01</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>14-28-51</td>\n",
       "      <td>one</td>\n",
       "      <td>long</td>\n",
       "      <td>385.0</td>\n",
       "      <td>80</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vvp01</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>15-12-23</td>\n",
       "      <td>one</td>\n",
       "      <td>short</td>\n",
       "      <td>347.0</td>\n",
       "      <td>74</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>vvp01</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>17-29-30</td>\n",
       "      <td>one</td>\n",
       "      <td>long</td>\n",
       "      <td>800.0</td>\n",
       "      <td>68</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gor01</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>15-55-31</td>\n",
       "      <td>one</td>\n",
       "      <td>long</td>\n",
       "      <td>660.0</td>\n",
       "      <td>97</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>gor01</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>15-22-3</td>\n",
       "      <td>two</td>\n",
       "      <td>long</td>\n",
       "      <td>530.0</td>\n",
       "      <td>82</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   animal  month  day      time    track segment  duration  n_cells  \\\n",
       "54  gor01      6    9  22-24-40      two   short    1620.0      203   \n",
       "1   gor01      6    7  16-40-19      two   short    1330.0      117   \n",
       "28  pin01     11    1  12-58-54  unknown    long    1670.0       49   \n",
       "29  pin01     11    1  12-58-54  unknown   short     925.0       49   \n",
       "0   gor01      6    7  16-40-19      two    long    1180.0      117   \n",
       "42  gor01      6    9   1-22-43      one    long    1012.0      203   \n",
       "53  gor01      6    9  22-24-40      two    long     912.0      203   \n",
       "43  gor01      6    9   1-22-43      one   short     617.0      203   \n",
       "18  gor01      6    8  21-16-25      two    long     720.0      171   \n",
       "60  vvp01      4    9  17-29-30      one   short     490.0       68   \n",
       "26  vvp01      4    9  16-40-54      two    long     861.0       41   \n",
       "19  gor01      6    8  21-16-25      two   short     457.0      171   \n",
       "24  gor01      6   12  16-53-46      two    long     470.0       81   \n",
       "49  vvp01      4   25  14-28-51      one    long     385.0       80   \n",
       "21  vvp01      4   16  15-12-23      one   short     347.0       74   \n",
       "59  vvp01      4    9  17-29-30      one    long     800.0       68   \n",
       "6   gor01      6   12  15-55-31      one    long     660.0       97   \n",
       "66  gor01      6   13   15-22-3      two    long     530.0       82   \n",
       "\n",
       "    n_placecells  n_PBEs  Notes  prescreen_z  \n",
       "54            61     301    NaN          NaN  \n",
       "1             46     277    NaN          NaN  \n",
       "28            21     238    NaN          NaN  \n",
       "29            26     222    NaN          NaN  \n",
       "0             43     150    NaN          NaN  \n",
       "42            62     117    NaN          NaN  \n",
       "53            66     103    NaN          NaN  \n",
       "43            71      91    NaN          NaN  \n",
       "18            82      57    NaN          NaN  \n",
       "60            32      46    NaN          NaN  \n",
       "26            25      42    NaN          NaN  \n",
       "19            64      37    NaN          NaN  \n",
       "24            36      36    NaN          NaN  \n",
       "49            32      36    NaN          NaN  \n",
       "21            24      34    NaN          NaN  \n",
       "59            34      33    NaN          NaN  \n",
       "6             40      32    NaN          NaN  \n",
       "66            37      31    NaN          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restrict sessions to explore to a smaller subset\n",
    "min_n_placecells = 20\n",
    "min_n_PBEs = 30 # 27 total events ==> minimum 21 events in training set\n",
    "\n",
    "df2_subset = df2[(df2.n_PBEs >= min_n_PBEs) & (df2.n_placecells >= min_n_placecells)]\n",
    "\n",
    "sessions = df2_subset['time'].values.tolist()\n",
    "segments = df2_subset['segment'].values.tolist()\n",
    "\n",
    "print('Evaluating subset of {} sessions'.format(len(sessions)))\n",
    "\n",
    "df2_subset.sort_values(by=['n_PBEs', 'n_placecells'], ascending=[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** it is relatively easy (syntax-wise) to score each session as a parallel task, but since the Bayesian scoring takes such a long time to compute, we can be more efficient (higher % utilization) by further parallelizing over events, and not just over sessions. This further level of parallelization makes the bookkeeping a little ugly, so I provide the code for both approaches here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parallelize_by_session = False\n",
    "parallelize_by_event = True\n",
    "\n",
    "n_jobs = 8 # set this equal to number of cores\n",
    "n_shuffles = 10 # 5000\n",
    "n_samples = 35000\n",
    "w=3 # single sided bandwidth (0 means only include bin who's center is under line, 3 means a total of 7 bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client('dask-scheduler:8786') # fill in value from dask-kubernetes startup if connecting remotely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parallelize_by_session:\n",
    "    #from joblib import Parallel, delayed \n",
    "    import distributed.joblib\n",
    "    from joblib import Parallel, parallel_backend, delayed\n",
    "\n",
    "\n",
    "    # A function that can be called to do work:\n",
    "    def work_sessions(arg):    \n",
    "\n",
    "        # Split the list to individual variables:\n",
    "        ii, bst, tc = arg    \n",
    "\n",
    "        scores, shuffled_scores, percentiles = nel.analysis.replay.score_Davidson_final_bst_fast(bst=bst,\n",
    "                                                                                            tuningcurve=tc,\n",
    "                                                                                            w=w,\n",
    "                                                                                            n_shuffles=n_shuffles,\n",
    "                                                                                            n_samples=n_samples)\n",
    "\n",
    "        return (ii, scores, shuffled_scores, percentiles)\n",
    "\n",
    "    # List of instances to pass to work():\n",
    "    parallel_sessions = [(ii, aux_data[session][segment]['PBEs'], aux_data[session][segment]['tc']) for (ii, (session, segment)) in enumerate(zip(sessions, segments))]\n",
    "\n",
    "    with parallel_backend('dask.distributed', scheduler_host='dask-scheduler:8786'):\n",
    "        # Anything returned by work() can be stored:\n",
    "        parallel_results = Parallel(n_jobs=n_jobs, verbose=51)(map(delayed(work_sessions), parallel_sessions))\n",
    "\n",
    "    # standardize parallel results\n",
    "    idx = [result[0] for result in parallel_results]\n",
    "\n",
    "    # check that parallel results came back IN ORDER:\n",
    "    if nel.utils.is_sorted(idx):\n",
    "        print('parallel results are ordered...')\n",
    "    else:\n",
    "        raise ValueError('results are not ordered! handle it here before proceeding...')\n",
    "\n",
    "    scores_bayes = [result[1] for result in parallel_results]\n",
    "    scores_bayes_shuffled = [result[2] for result in parallel_results]\n",
    "    scores_bayes_percentile = [result[3] for result in parallel_results]\n",
    "\n",
    "    results = dict()\n",
    "    for ii, (session, segment) in enumerate(zip(sessions, segments)):\n",
    "        try:\n",
    "            results[session][segment] = dict()\n",
    "        except KeyError:\n",
    "            results[session] = dict()    \n",
    "            results[session][segment] = dict()\n",
    "        results[session][segment]['scores_bayes'] = scores_bayes[ii]\n",
    "        results[session][segment]['scores_bayes_shuffled'] = scores_bayes_shuffled[ii]\n",
    "        \n",
    "        results[session][segment]['scores_bayes_percentile'] = scores_bayes_percentile[ii]\n",
    "\n",
    "    print('done packing results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9b603c3941e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mparallel_results_future\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork_events\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mparallel_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_results_future\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# standardize parallel results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, maxsize, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             return self.sync(self._gather, futures, errors=errors,\n\u001b[1;32m   1388\u001b[0m                              \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m                              asynchronous=asynchronous)\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoroutine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if parallelize_by_event:\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    \n",
    "    #from joblib import Parallel, delayed \n",
    "    #import distributed.joblib\n",
    "    #from joblib import Parallel, parallel_backend, delayed\n",
    "\n",
    "    # A function that can be called to do work:\n",
    "    def work_events(arg):    \n",
    "        # Split the list to individual variables:\n",
    "        session, segment, ii, bst, tc = arg\n",
    "        scores, shuffled_scores, percentiles = nel.analysis.replay.score_Davidson_final_bst_fast(bst=bst,\n",
    "                                                                                            tuningcurve=tc,\n",
    "                                                                                            w=w,\n",
    "                                                                                            n_shuffles=n_shuffles,\n",
    "                                                                                            n_samples=n_samples)\n",
    "\n",
    "        t01 = time.time()\n",
    "        return (session, segment, ii, scores, shuffled_scores, percentiles)\n",
    "\n",
    "    # List of instances to pass to work():\n",
    "    # unroll all events:\n",
    "    parallel_events = []\n",
    "    for session, segment in zip(sessions, segments):\n",
    "        for nn in range(aux_data[session][segment]['PBEs'].n_epochs):\n",
    "            parallel_events.append((session, segment, nn, aux_data[session][segment]['PBEs'][nn], aux_data[session][segment]['tc']))\n",
    "\n",
    "    #with parallel_backend('dask.distributed', scheduler_host='dask-scheduler:8786'):\n",
    "        # Anything returned by work() can be stored:\n",
    "        #parallel_results = Parallel(n_jobs=n_jobs, verbose=51)(map(delayed(work_events), parallel_events))\n",
    "        \n",
    "    parallel_results_future = client.map(work_events, parallel_events)\n",
    "    parallel_results = client.gather(parallel_results_future)\n",
    "    \n",
    "    # standardize parallel results\n",
    "    bdries_ = [aux_data[session][segment]['PBEs'].n_epochs for session, segment in zip(sessions, segments) ]\n",
    "    bdries = np.cumsum(np.insert(bdries_,0,0))\n",
    "    bdries\n",
    "\n",
    "    sessions_ = np.array([result[0] for result in parallel_results])\n",
    "    segments_ = np.array([result[1] for result in parallel_results])\n",
    "    idx = [result[2] for result in parallel_results]\n",
    "\n",
    "    scores_bayes_evt = np.array([float(result[3]) for result in parallel_results])\n",
    "    scores_bayes_shuffled_evt = np.array([result[4].squeeze() for result in parallel_results])\n",
    "    scores_bayes_percentile_evt = np.array([float(result[5]) for result in parallel_results])\n",
    "\n",
    "    results = {}\n",
    "    for nn in range(len(bdries)-1):\n",
    "        session = np.unique(sessions_[bdries[nn]:bdries[nn+1]])\n",
    "        if len(session) > 1:\n",
    "            raise ValueError(\"parallel results in different format / order than expected!\")\n",
    "        session = session[0]\n",
    "        segment = np.unique(segments_[bdries[nn]:bdries[nn+1]])\n",
    "        if len(segment) > 1:\n",
    "            raise ValueError(\"parallel results in different format / order than expected!\")\n",
    "        segment = segment[0]\n",
    "        try:\n",
    "            results[session][segment]['scores_bayes'] = scores_bayes_evt[bdries[nn]:bdries[nn+1]]\n",
    "        except KeyError:\n",
    "            try:\n",
    "                results[session][segment] = dict()\n",
    "                results[session][segment]['scores_bayes'] = scores_bayes_evt[bdries[nn]:bdries[nn+1]]\n",
    "            except KeyError:\n",
    "                results[session] = dict()\n",
    "                results[session][segment] = dict()\n",
    "                results[session][segment]['scores_bayes'] = scores_bayes_evt[bdries[nn]:bdries[nn+1]]\n",
    "\n",
    "        results[session][segment]['scores_bayes_shuffled'] = scores_bayes_shuffled_evt[bdries[nn]:bdries[nn+1]]\n",
    "        results[session][segment]['scores_bayes_percentile'] = scores_bayes_percentile_evt[bdries[nn]:bdries[nn+1]]\n",
    "\n",
    "    print('done packing results')\n",
    "\n",
    "t1 = time.time()    \n",
    "print('Elapsed time ', t1 - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jar = nel.ResultsContainer(results=results, description='gor01 and vvp01 speed restricted results for best 20 candidate sessions')\n",
    "jar.save_pkl('score_bayes_all_sessions.nel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
